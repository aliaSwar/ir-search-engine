{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe06ef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bc8a3",
   "metadata": {},
   "source": [
    "## Inverted Index\n",
    "Inverted index is a data structure used in information retrieval to index the content of documents. The inverted index stores a mapping from each term to the documents that contain it. This makes it possible to quickly look up all the documents that contain a given term.\n",
    "\n",
    "Let's start by defining a simple example corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2043699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    'doc1': 'apple banana apple',\n",
    "    'doc2': 'banana cherry',\n",
    "    'doc3': 'apple cherry'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db656814",
   "metadata": {},
   "source": [
    "To create an inverted index from this corpus, we can follow these steps:\n",
    "\n",
    "Tokenize the documents into terms. In this example, we'll use whitespace as the delimiter. you can use a tokenizer from nltk of write your own tokenizer \n",
    "Create a dictionary to store the inverted index.\n",
    "For each term in each document, add the document to the inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b23348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    inverted_index = defaultdict(list)\n",
    "    for doc_id, doc_content in corpus.items():\n",
    "        ## add some text processing , Tokenize, remove stop words ... to create a list of cleaned terms\n",
    "        ## write your code here\n",
    "        terms = word_tokenize(doc_content)\n",
    "        for term in terms:\n",
    "            inverted_index[term].append(doc_id)\n",
    "    return dict(inverted_index)\n",
    "\n",
    "inverted_index = create_inverted_index(corpus)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2a7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should output the followings:\n",
    "# {\n",
    "#     'apple': ['doc1', 'doc3'],\n",
    "#     'banana': ['doc1', 'doc2'],\n",
    "#     'cherry': ['doc2', 'doc3']\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3d3d0",
   "metadata": {},
   "source": [
    "## Term Frequency\n",
    "Term frequency (TF) is a measure of how often a term appears in a document. It is used in information retrieval to help rank documents that match a query. The basic idea is that documents that contain a term more frequently are more likely to be relevant to a query that contains that term.\n",
    "\n",
    "To calculate the term frequency of each term in a document, we can follow these steps:\n",
    "\n",
    "Tokenize the document into terms.\n",
    "Count the number of occurrences of each term in the document.\n",
    "Divide each term count by the total number of terms in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c545c373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         tf[term] \u001b[39m=\u001b[39m terms\u001b[39m/\u001b[39mterm_count\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\n\u001b[1;32m----> 9\u001b[0m tf_doc1 \u001b[39m=\u001b[39m calculate_tf(corpus[\u001b[39m'\u001b[39m\u001b[39mdoc1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[39m# print(tf_doc1)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_tf(document):\n",
    "    tf = {}\n",
    "    terms = document.split()\n",
    "    term_count = len(terms)\n",
    "    for term in terms:\n",
    "        tf[term] =terms.count(term)/term_count\n",
    "    return tf\n",
    "\n",
    "tf_doc1 = calculate_tf(corpus['doc1'])\n",
    "# print(tf_doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89c292",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Term frequency-inverse document frequency (TF-IDF) is a measure of the importance of a term in a document. It is used in information retrieval to help rank documents that match a query. The basic idea is that terms that appear more frequently in a document are more important, but terms that appear in many documents are less important.\n",
    "\n",
    "To calculate the TF-IDF score of each term in a document, we can follow these steps:\n",
    "\n",
    "Calculate the term frequency (TF) of each term in the document.\n",
    "Calculate the inverse document frequency (IDF) of each term across all documents.\n",
    "Multiply the TF and IDF of each term to get the TF-IDF score of each term in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397cbc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 0.0, 'banana': 0.13515503603605478}\n"
     ]
    }
   ],
   "source": [
    "# write \n",
    "def calculate_idf(corpus):\n",
    "    idf = {}\n",
    "    n_docs = len(corpus)\n",
    "    inverted_index = creat_inverted_index(corpus)  # create the inverted index for the whole document.\n",
    "\n",
    "    for term, doc_ids in inverted_index.items():\n",
    "        idf[term] = math.log10(n_docs / len(doc_ids)) # logarithm to base 10.\n",
    "\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(document, corpus):\n",
    "    tfidf = {}\n",
    "    tf = calculate_tf\n",
    "    idf = calculate_idf\n",
    "    for term in tf:\n",
    "        tfidf[term] = tf(document, term) * idf(corpus) # tf * idf.\n",
    "    return tfidf\n",
    "\n",
    "tfidf_doc1 = calculate_tfidf(corpus['doc1'], corpus)\n",
    "print(tfidf_doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954251f8",
   "metadata": {},
   "source": [
    "# sklearn Library\n",
    "now user sklearn library to calcuate tf and tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf69160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         apple    banana    cherry\n",
      "doc1  0.894427  0.447214  0.000000\n",
      "doc2  0.000000  0.707107  0.707107\n",
      "doc3  0.707107  0.000000  0.707107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a simple example corpus\n",
    "corpus = {\n",
    "    'doc1': 'apple banana apple',\n",
    "    'doc2': 'banana cherry',\n",
    "    'doc3': 'apple cherry'\n",
    "}\n",
    "\n",
    "# Create a list of documents\n",
    "documents = list(corpus.values())\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = ?\n",
    "\n",
    "# Fit the vectorizer to the documents\n",
    "tfidf_matrix = ?\n",
    "\n",
    "# Convert the TF-IDF matrix to a Pandas DataFrame\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names(), index=corpus.keys())\n",
    "\n",
    "# Print the resulting TF-IDF scores\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define a simple example corpus\n",
    "corpus = {\n",
    "    'doc1': 'apple banana apple',\n",
    "    'doc2': 'banana cherry',\n",
    "    'doc3': 'apple cherry'\n",
    "}\n",
    "\n",
    "# Create a list of documents\n",
    "documents = list(corpus.values())\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = ?\n",
    "\n",
    "# Fit the vectorizer to the documents\n",
    "tf_matrix = ?\n",
    "\n",
    "# Convert the TF matrix to a Pandas DataFrame\n",
    "df = pd.DataFrame(tf_matrix.toarray(), columns=vectorizer.get_feature_names(), index=corpus.keys())\n",
    "\n",
    "# Normalize the TF scores by dividing each row by its sum\n",
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "# Print the resulting TF scores\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
